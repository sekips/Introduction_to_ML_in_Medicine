{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "MedRWD_ML_20210928_記入済み.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCRGyCxnMzCy"
      },
      "source": [
        "# 医用機械学習入門の手引き\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frjpgyoQd0cX"
      },
      "source": [
        "## 0.Google colaboratoryの設定\n",
        "実習にあたってまず下記の設定をして　GPUを使えるようにします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhWiMWKCc1hR"
      },
      "source": [
        "0-1.画面左上のメニューバーからランタイムを選択してください。\n",
        "\n",
        "<figure>\n",
        "<left>\n",
        "<img src='https://drive.google.com/uc?export=view&id=19uyNdEhnz3MFkhcTgpmCKAp3xGOZUlEh' width=50%>\n",
        "</left>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHxuxtvydUtw"
      },
      "source": [
        "0-2.開いたドロップダウンメニューから、「ランタイムのタイプを変更」をクリックしてください。\n",
        "\n",
        "<figure>\n",
        "<left>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1GCZ-fTrIgFCHhyJFtulGinPiCsXHsYMK' width=50%>\n",
        "</left>\n",
        "</figure>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKTlf9oSeFst"
      },
      "source": [
        "0-3.「ノートブックの設定」というウィンドウが開くので、ハードウェアアクセラレータが「GPU」になっていることを確認して右下の「保存」を押してください。「GPU」に設定されていない場合はハードウェアアクセラレータに「GPU」を選択して、右下の「保存」を押してください。\n",
        "<figure>\n",
        "<left>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1BVRwK1TUiZdcS8ptpDCrbl14BMvpXbOL' width=50%>\n",
        "</left>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnul_vaveuO2"
      },
      "source": [
        "0-4.ノートブック画面右上の「接続」をクリックしてください。\n",
        "<figure>\n",
        "<left>\n",
        "<img src='https://drive.google.com/uc?export=view&id=17lgUS5Lfl0F3PEtTV1b79qpI1O_AVF0o' width=50%>\n",
        "</left>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnmt1ytCfJgu"
      },
      "source": [
        "0-5.ノートブック画面右上の「接続」の表示が変わり、緑色のチェックが表示され、RAMとディスクという表示になったことを確認してください。\n",
        "<figure>\n",
        "<left>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1eEOOY6JgAG15A2XRn0irijrHlFtSwmH-' width=50%>\n",
        "</left>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17aKWjwWfhc3"
      },
      "source": [
        "0-6.ノートブック画面右上の、今表示が変わったRAMとディスクという表示の上にカーソルを合わせると、「接続先 Python 3 Google Compute Engine バックエンド (GPU)」という表示が出ることを確認してください。\n",
        "<figure>\n",
        "<left>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1_mWrsnpRcUpfCUcA_E1DGvm7YIgx5hGS' width=50%>\n",
        "</left>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtJl3Vb3ggZP"
      },
      "source": [
        "<font color=\"#ff4500\"><b>注意！！！！</b></font>\n",
        "しばらくGPUを使用しない状態が続くと、下記のような警告がGoogle colaboratoryの画面の左下に表示されますが、表示された時は「×」を押して消してください。<font color=\"#ff4500\"><b>絶対に「標準ランタイムに切り替える」をクリックしないでください。</b></font>(もし間違えて押してしまった場合には、出てきたウィンドウで「GPUランタイムを継続する」を押して戻ってください。「標準ランタイムに変更する」を選択してしまうと、実行したスクリプトも全て最初からやり直しになりますので、0-1のランタイムの接続からやり直してください。)\n",
        "<figure>\n",
        "<left>\n",
        "<img src='https://drive.google.com/uc?export=view&id=17kmRjBgA4tYhPZls5krRT3l8RF5yb1Rl' width=50%>\n",
        "</left>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jB2XO0VW_KO"
      },
      "source": [
        "ここからは実習のスクリプトを実行していきます。まず、mnist datasetという手書きの数字画像のデータを使って、kerasとtensorflowを使った畳み込みニューラルネットワークで分類を行います。その次にNIHの胸部レントゲン画像セットを使って同様の手法で分類を行います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VxTFNUkHxMS"
      },
      "source": [
        "## 1.必要なモジュールのimport\n",
        "\n",
        "データ前処理及びニューラルネットワークの学習のために必要な各種モジュールをインポートします。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9xyPzEblPac"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import scipy\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import imageio\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.models import Model, model_from_json, Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "#実習用に下記でランダムシードを固定する。\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR9qvyIAIIbw"
      },
      "source": [
        "## 2.MNISTデータの読み込み\n",
        "まずmnist dataセットを使って畳み込みニューラルネットワークで分類をしてみます。mnist.load_data()は60,000枚の28x28ピクセルの白黒画像データとその正解の数字，10,000枚のテスト用画像データとその正解の数字を読みこむ関数です。 下記のように実行してデータを読みこみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3jTP_vpIEkt"
      },
      "source": [
        "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1pGB_M_IynW"
      },
      "source": [
        "読み込んだデータはnumpyのndarray形式になっています。shapeを使ってデータの次元数と各次元のサイズを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vhRff77Itnm"
      },
      "source": [
        "print('X_train_mnistの各次元のサイズ: ', X_train_mnist.shape)\n",
        "print('y_train_mnistの各次元のサイズ: ', y_train_mnist.shape)\n",
        "print('X_test_mnistの各次元のサイズ: ', X_test_mnist.shape)\n",
        "print('y_test_mnistの各次元のサイズ: ', y_test_mnist.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuvVq3hRLTSO"
      },
      "source": [
        "sklearnのtrain_test_splitを用いてチューニング用データ(`X_tuning_mnist`、`y_tuning_mnist`)を学習用データ(`X_train_mnist`、`y_train_mnist`)から切り分けます。(Holdout mothodです)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mByMZXccLIZm"
      },
      "source": [
        "X_train_mnist, X_tuning_mnist, y_train_mnist, y_tuning_mnist = train_test_split(X_train_mnist, y_train_mnist, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pagIQFzCfaJ7"
      },
      "source": [
        "チューニング用データを切り分けた後に同様にデータの次元数を確認します。(ndarrayのデータの変形をした場合には必ずshapeで処理後の次元数が合っているかを確認します。)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ1wY5aBLZAE"
      },
      "source": [
        "print('X_train_mnistの各次元のサイズ: ', X_train_mnist.shape)\n",
        "print('y_train_mnistの各次元のサイズ: ', y_train_mnist.shape)\n",
        "print('X_tuning_mnistの各次元のサイズ: ', X_tuning_mnist.shape)\n",
        "print('y_tuning_mnistの各次元のサイズ: ', y_tuning_mnist.shape)\n",
        "print('X_test_mnistの各次元のサイズ: ', X_test_mnist.shape)\n",
        "print('y_test_mnistの各次元のサイズ: ', y_test_mnist.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCnUt228JHyU"
      },
      "source": [
        "## 3.読み込んだデータの確認\n",
        "読み込んだMNISTのデータのうち、X_trainの最初の20枚の画像を下記のプログラムで描出してます。0〜9までの手書き文字のデータであることが確かに確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6nR6tenJAqu"
      },
      "source": [
        "fig = plt.figure(figsize=(12, 40))\n",
        "\n",
        "for i in range(20):\n",
        "    plt.subplot(20, 5, i+1)\n",
        "    plt.imshow((X_train_mnist[i]).astype(np.int32).reshape(28, 28), cmap='gray')\n",
        "    plt.title(\"No.{0}\".format(i))\n",
        "    plt.axis(\"off\")\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1TKTJ1GMVsx"
      },
      "source": [
        "## 4.読み込んだデータを畳み込みニューラルネットワークで学習するための形に変形する\n",
        "\n",
        "畳み込みニューラルネットワーク(CNN, Convolutional Neural Network)では、データの2次元構造を保持したままニューラルネットワークにデータを入力します。そのため、読み込んだmnist datasetを適した形に変形する必要があります。\n",
        "\n",
        "numpyのndarrayはreshapeメソッドで形を変形できます。`X_train_mnist`は、例えば48000枚の28x28ピクセルの画像データを保持していて、現在その各次元のサイズは(48000,28, 28)でこれが28x28の配列が48000セットある状態を示します。\n",
        "    \n",
        "畳み込みニューラルネットワークに入れるに当たって、reshapeメソッドを用いて次元数と各次元のサイズを(枚数、28, 28, チャンネル数)の形にする必要があります。（チャンネル数は白黒画像であれば1、カラー画像であれば3となります。今回は白黒画像なのでチャンネル数=1です。）\n",
        "\n",
        "shapeは各次元のサイズをタプルデータ型で返します。`X_train_mnist.shape[0]`は今回のケースでは画像の枚数を示します。`X_train_mnist.shape = (48000, 28, 28)`であり、`X_train_mnist.shape[0] = 48000`、`X_train_mnist.shape[1] = 28`、`X_train_mnist.shape[2] = 28`となります。\n",
        "     \n",
        "Tensorflowは32ビット浮動小数点の数字を受け入れるため、.astype('float32')で32ビット浮動小数点の数字にします。\n",
        "     \n",
        "X_train、X_testに含まれる数字はピクセル値であり、0-255の整数ですが、計算の便宜上-1から1の間に圧縮します。 \n",
        "     \n",
        "y_train、y_testは0-9の整数の羅列ですが、ニューラルネットワークの出力と比較するため、to_categofical関数で10分類のone-hot表現に変形します。one-hot表現では、例えば4という数字は`[0,0,0,0,1,0,0,0,0,0]`という表現に置き換わります。\n",
        "\n",
        "下記を実行してデータの次元と各次元のサイズを変更します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVN7dca0MTXb"
      },
      "source": [
        "#X_train_mnistの次元を(枚数、28, 28, チャンネル数)に変換したのち、0-255のピクセル値を-1から1の値にスケーリングする\n",
        "X_train_mnist = X_train_mnist.reshape(X_train_mnist.shape[0],28,28,1).astype('float32')\n",
        "X_train_mnist = ((X_train_mnist/255.)-0.5)*2.\n",
        "\n",
        "#y_train_mnistをone-hot表現に変換してy_train_mnist_ohという変数に入れておく\n",
        "y_train_mnist_oh = to_categorical(y_train_mnist)\n",
        "\n",
        "#X_tuning_mnistの次元を(枚数、28, 28, チャンネル数)に変換したのち、0-255のピクセル値を-1から1の値にスケーリングする\n",
        "X_tuning_mnist = X_tuning_mnist.reshape(X_tuning_mnist.shape[0],28,28,1).astype('float32')\n",
        "X_tuning_mnist = ((X_tuning_mnist/255.)-0.5)*2.\n",
        "\n",
        "#y_tuning_mnistをone-hot表現に変換してy_tuning_mnist_ohという変数に入れておく\n",
        "y_tuning_mnist_oh = to_categorical(y_tuning_mnist)\n",
        "\n",
        "#X_test_mnistの次元を(枚数、28, 28, チャンネル数)に変換したのち、0-255のピクセル値を-1から1の値にスケーリングする\n",
        "X_test_mnist = X_test_mnist.reshape(X_test_mnist.shape[0],28,28,1).astype('float32')\n",
        "X_test_mnist = ((X_test_mnist/255.)-0.5)*2.\n",
        "\n",
        "#y_test_mnistをone-hot表現に変換してy_test_mnist_ohという変数に入れておく\n",
        "y_test_mnist_oh = to_categorical(y_test_mnist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRH00qW1f7oS"
      },
      "source": [
        "データを整形した後には必ず.shapeで次元数と各次元のサイズを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc3vSXabOmH5"
      },
      "source": [
        "print('X_train_mnistの各次元のサイズ: ', X_train_mnist.shape)\n",
        "print('y_train_mnistの各次元のサイズ: ', y_train_mnist.shape)\n",
        "print('y_train_mnist_ohの各次元のサイズ: ', y_train_mnist_oh.shape)\n",
        "print()\n",
        "print('X_tuning_mnistの各次元のサイズ: ', X_tuning_mnist.shape)\n",
        "print('y_tuning_mnistの各次元のサイズ: ', y_tuning_mnist.shape)\n",
        "print('y_tuning_mnist_ohの各次元のサイズ: ', y_tuning_mnist_oh.shape)\n",
        "print()\n",
        "print('X_test_mnistの各次元のサイズ: ', X_test_mnist.shape)\n",
        "print('y_test_mnistの各次元のサイズ: ', y_test_mnist.shape)\n",
        "print('y_test_mnist_ohの各次元のサイズ: ', y_test_mnist_oh.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8XSBorYJomm"
      },
      "source": [
        "## 5.Kerasを用いてニューラルネットを組む\n",
        "    \n",
        "Kerasを用いて畳み込みニューラルネットワークを組んでいきます。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-I5cTbb1U_P"
      },
      "source": [
        "mnist_model = Sequential()\n",
        "mnist_model.add(Reshape((784,), input_shape=(28, 28, 1)))\n",
        "mnist_model.add(Dense(units=200, activation=\"relu\"))\n",
        "mnist_model.add(Dense(units=200, activation=\"relu\"))\n",
        "mnist_model.add(Dense(units=10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7vV4yMm2JFq"
      },
      "source": [
        "kerasのモデルはsummaryメソッドで構造を表形式で表示できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q49r4ibl2CsX"
      },
      "source": [
        "mnist_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx5msl4qKO9a"
      },
      "source": [
        "## 6.作成したニューラルネットをどのように学習させるかを設定する\n",
        "\n",
        "上のプログラムで作成したニューラルネットを、どのように学習させるか設定します。\n",
        "\n",
        "具体的には.compile()で損失関数(loss)、最適化アルゴリズム(optimizer)、評価関数(metrics)を与えてニューラルネットを完成させます。\n",
        "\n",
        "一般的には分類問題であればlossはcategorical_crossentropy(2分類であればbinary_crossentropy)を用いる。\n",
        "\n",
        "oprimizerは下記では確率的勾配降下法（SGD, Stochastic Gradient Descent）を用いており、lrはlearning rateを示します。learning rateが大きいほど、一回の学習でのパラメータの更新は大きくなります。\n",
        "\n",
        "分類問題であるため、評価関数はとりあえずaccuracyを用いることにします。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny1-VAc5KEz2"
      },
      "source": [
        "mnist_model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(learning_rate=0.01), metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yECzkZWwLsGy"
      },
      "source": [
        "## 7.学習を行う\n",
        "kerasのモデルはfitメソッドを用いて学習を行うことができます。学習データ、正解データ、エポック数、バッチサイズを与えて学習を開始します。ここではとりあえずエポック数は10とします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uf8JkhhLkYt"
      },
      "source": [
        "mnist_model.fit(X_train_mnist, \n",
        "                y_train_mnist_oh, \n",
        "                epochs=10, \n",
        "                validation_data=(X_tuning_mnist, y_tuning_mnist_oh), \n",
        "                batch_size=128, \n",
        "                shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhC1vUwlPsMB"
      },
      "source": [
        "## 8.テストデータを用いて学習結果を検証する\n",
        "あらかじめとっておいたテスト用データ(`X_test_mnist`、`y_test_mnist`)を用いて、今学習させたニューラルネットワークの正確性を検証します。（本来であればハイパーパラメータを調整してベストのハイパーパラメータを決めて、`X_train_mnist`と`X_tuning_mnist`を合わせたデータでモデルを学習させて、最後にテスト用データで検証します）\n",
        "モデルのpredictメソッドにテスト用データを与え、予測結果を出力することができます。\n",
        "    \n",
        "y_pred_mnist（モデルによる予測）とy_test_mnist（正解データ）から評価指標を算出します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PKsB-48PjlS"
      },
      "source": [
        "y_pred_mnist = mnist_model.predict(X_test_mnist, batch_size=128)\n",
        "y_pred_mnist = np.argmax(y_pred_mnist, axis=1)\n",
        "print('accuracy:', accuracy_score(y_test_mnist, y_pred_mnist))    \n",
        "print('f1 score:',f1_score(y_test_mnist, y_pred_mnist, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIpca1TNwK1k"
      },
      "source": [
        "画像を実際に1枚選んで予測させてみましょう。画像のndarrayを入力すると、画像を表示する関数show_imgを作って画像を表示してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nrzmL-kyi7A"
      },
      "source": [
        "def show_img(img_arr):\n",
        "    plt.imshow((((img_arr)/2 + 0.5)*255).astype(np.int32).reshape(28, 28), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JwnYO5jzJzA"
      },
      "source": [
        "show_img(X_test_mnist[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niPNy3p1z7xy"
      },
      "source": [
        "この画像をpredictメソッドで作ったモデルで予測させた結果を見てみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFiiA1p9wPM8"
      },
      "source": [
        "np.argmax(mnist_model.predict(X_test_mnist[0].reshape(1, 28, 28, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-ayLKv64Guv"
      },
      "source": [
        "## 9.畳み込みニューラルネットワークを使ってみる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGaSaOvR1Sw5"
      },
      "source": [
        "畳み込みニューラルネットワークでは、一定の大きさのフィルター(重みの集まり)を少しずつずらしながら画像に当てていき、計算を進めていきます。\n",
        "\n",
        "畳み込みの計算では、下記のようにフィルターを当てたときのそれぞれの数値の積の合計を計算して出力しています。フィルター部分が、学習で調整する畳み込みニューラルネットワークのパラメータになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDkUQbo7ikx8"
      },
      "source": [
        "<figure>\n",
        "<left>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1G8tbbn5Tvxye8SVY1GrLH81WBOQBJY0-' width=50%>\n",
        "</left>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RxKxyVUm-yH"
      },
      "source": [
        "Max-poolingの計算では、下記のように決められたサイズの中の最大値を出力しています。MAX poolingの計算にはパラメータはありません。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apP0l8TSkHBx"
      },
      "source": [
        "<figure>\n",
        "<left>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1K-OQfyJt4-BdaSDrSZs5qQaZnmviCWg2' width=35%>\n",
        "</left>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czx29cBhgaST"
      },
      "source": [
        "実際に作成した下記のニューラルネットワークでは、最初の畳み込み層(Conv2D)は28x28ピクセルの画像に3x3ピクセルのフィルターをずらしながら当てていくことで26x26ピクセルのデータが出力されます。ここの畳み込み層では16種類のフィルターを準備して、26x26ピクセルのデータを16枚出力するようになっています。\n",
        "\n",
        "MaxPooling2Dでは定められた範囲内のうち最大のピクセルのみを選んで残します。下記のConv2Dの次のMaxPooling2Dでは26x26ピクセルのデータが13x13ピクセルのデータに縮小されることになります。その結果出力されるのは13x13ピクセルのデータが16枚ということになります。\n",
        "\n",
        "次の畳み込み層では再び1種類あたり3x3ピクセルx16枚のフィルターを当てていき、13x13ピクセルのデータは11x11ピクセルとなります。ここの畳み込み層では32種類のフィルターを当てるため、11x11ピクセルのデータを32枚出力することになります。その次のMaxPooling2Dで5x5ピクセルのデータが32枚出力されます。\n",
        "\n",
        "最後にflattenによって全ての数値を1次元に並べます。flattenによって5x5x32 = 800 個のunitが並んでいる状態となります。\n",
        "\n",
        "その次のDense層で800個のunitは256個のunitへ伝達され、最終的に10個のunitへ入力されてsoftmax関数(合計で1になるようにする関数)で出力されます。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1TYtErVJgRV"
      },
      "source": [
        "mnist_model_cnn = Sequential()\n",
        "mnist_model_cnn.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "mnist_model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "mnist_model_cnn.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "mnist_model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "mnist_model_cnn.add(Flatten())\n",
        "\n",
        "mnist_model_cnn.add(Dense(units=256, activation='relu'))\n",
        "mnist_model_cnn.add(Dense(units=10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZ7nZbNDjFa"
      },
      "source": [
        "上記のモデルは図示化すると下のようになります。\n",
        "<figure>\n",
        "<left>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1FLBlSgoOdA4DgQWB5rtt8Y6mLTMRtPna' width=100%>\n",
        "</left>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIPLvwaUocql"
      },
      "source": [
        "上述した詳しいニューラルネットワークの構造を表形式で出力してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LB2jkFGoXU-"
      },
      "source": [
        "mnist_model_cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpDKWx9qFG_d"
      },
      "source": [
        "先ほどと同様に、上のプログラムで作成した畳み込みニューラルネットを、どのように学習させるか設定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VutubDom2okB"
      },
      "source": [
        "mnist_model_cnn.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr=0.01), metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezwRuLueFQEV"
      },
      "source": [
        "先ほどと同じくfitメソッドを用いて学習データ、正解データ、エポック数、バッチサイズを与えて学習を開始します。エポック数はここでもいったん10としておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9hPir3W2onq"
      },
      "source": [
        "mnist_model_cnn.fit(X_train_mnist, \n",
        "                    y_train_mnist_oh, \n",
        "                    epochs=10, \n",
        "                    validation_data=(X_tuning_mnist, y_tuning_mnist_oh), \n",
        "                    batch_size=128, \n",
        "                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9JUPhkwFhn_"
      },
      "source": [
        "y_pred_mnist_cnn（畳み込みニューラルネットワークモデルによる予測）とy_test_mnist（正解データ）から評価指標を算出します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR7LooyS2oqz"
      },
      "source": [
        "y_pred_mnist_cnn = mnist_model_cnn.predict(X_test_mnist, batch_size=128)\n",
        "y_pred_mnist_cnn = np.argmax(y_pred_mnist_cnn, axis=1)\n",
        "print('accuracy:', accuracy_score(y_test_mnist, y_pred_mnist_cnn))    \n",
        "print('f1 score:',f1_score(y_test_mnist, y_pred_mnist_cnn, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl3FUVGPSvVH"
      },
      "source": [
        "## 10.NIH Chest X-ray Dataset \n",
        "30,805人の患者の112,120枚の正面視X線画像からなるデータセットで、Atelectasis, Consolidation, Infiltration, Pneumothorax, Edema, Emphysema, Fibrosis, Effusion, Pneumonia, Pleural_thickening, Cardiomegaly, Nodule, Mass, Herniaの14のラベルが読影レポートからのテキストマイニングで付けられています。\n",
        "このデータセットは、NIH クリニカル センターから提供されており、NIH のサイト（ https://nihcc.app.box.com/v/ChestXray-NIHCC ）から入手できるようになっています。\n",
        "\n",
        "Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, Ronald Summers, ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases, IEEE CVPR, pp. 3462-3471, 2017"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfb1qkF9SyM_"
      },
      "source": [
        "まず事前にこちらで作成した画像データとラベルデータのzipファイルをダウンロードします。元は1024x1024ピクセルの画像データですが、今回は実習用に64x64ピクセルに解像度を落としてあります。また、ラベルに関する情報はcsvファイルに記載してあります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plLFX5S-ubId"
      },
      "source": [
        "今回は、異常所見のラベルが何もついていない画像であれば 0 、何かしら異常を示すラベルがついていれば 1 というラベルを用いて、畳み込みニューラルネットワークを使って分類を学習してみることにします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLcyl8I_h_Oi"
      },
      "source": [
        "FILE_ID = \"1uW9eivQ9MtFvHVirC3YTByxhV5W8CqKT\"\n",
        "FILE_NAME = \"medrwd_ml.zip\"\n",
        "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$FILE_ID\" -O $FILE_NAME && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60Jh1J86TLzx"
      },
      "source": [
        "ダウンロードしたzipファイルを解凍します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmpvpe8UkAe-"
      },
      "source": [
        "! unzip medrwd_ml.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW_3bnTUTeUD"
      },
      "source": [
        "学習用のデータの情報、テスト用のデータの情報が記載されたCSVファイルをpandasのread_csv関数で読みこみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp0olSfjMzCz"
      },
      "source": [
        "df_train = pd.read_csv(\"img_labels_train.csv\")\n",
        "df_test = pd.read_csv(\"img_labels_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BMKGztVt3oY"
      },
      "source": [
        "読み込んだCSVファイルの中身を確認してみます。一番右側のlabelというカラムはこちらで追加したカラムで、異常所見のラベルが何もついていない画像であれば 0 、何かしら異常を示すラベルがついていれば 1 となっています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y-BgoKBPkSY"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsgsX63-kWXL"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRoV-HNVM77"
      },
      "source": [
        "学習用データの最初の20枚について画像データを表示してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPwo22E7T1I-"
      },
      "source": [
        "fig = plt.figure(figsize=(12, 40))\n",
        "\n",
        "for i in range(20):\n",
        "    plt.subplot(20, 5, i+1)\n",
        "    img = imageio.imread(os.path.join('train_img_64', df_train.loc[i, 'Image Index']))\n",
        "    plt.imshow(img)\n",
        "    plt.gray()\n",
        "    plt.title(str(i) + ': ' + df_train.loc[i, 'Finding Labels'])\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoeoMWlkWEWw"
      },
      "source": [
        "下記を実行して学習用の画像が入っているtrain_img_64ディレクトリから、画像をnumpyのndarray形式で全て読みこみ、img_array_trainの変数に入れます。下記では読み込み用にread_imgという関数を作り、画像読み込み時に画像データをニューラルネットワークのための(枚数、64、64、チャンネル数)の形に変換しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UGCXojyMzC-"
      },
      "source": [
        "def read_img(path, img_name):\n",
        "    img = imageio.imread(os.path.join(path, img_name))\n",
        "    img = Image.fromarray(img).resize((64, 64))\n",
        "    img = img.convert('L')\n",
        "    img = np.array(img).reshape(1, 64, 64, 1)\n",
        "\n",
        "    return img\n",
        "\n",
        "img_list = []\n",
        "\n",
        "for i in df_train['Image Index']:\n",
        "    img = read_img('train_img_64', i)\n",
        "    img_list.append(img)\n",
        "\n",
        "img_array_train = np.concatenate(img_list, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MDze4mRWoey"
      },
      "source": [
        "読み込んだndarrayの次元数と各次元のサイズを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "316kWFXEhxDU"
      },
      "source": [
        "print(img_array_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f-i2yaMWwT2"
      },
      "source": [
        "読み込んだCSVファイルの\"label\"カラム（No Findingであれば 0 、何かしら異常があれば 1 ）をlabels_trainという名前の変数に入れておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-SqFw04MzDK"
      },
      "source": [
        "labels_train = df_train['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uEACOA7XFqn"
      },
      "source": [
        "読み込んだラベルデータの次元数と各次元のサイズを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eazR4vPaMzDM"
      },
      "source": [
        "print(labels_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ehvqd3yXM37"
      },
      "source": [
        "読み込んだデータを、学習用データとチューニング用データに切り分けます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42kUEZlxldSr"
      },
      "source": [
        "X_train, X_tuning, y_train, y_tuning = train_test_split(img_array_train, labels_train, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyeRtN_mXWEd"
      },
      "source": [
        "データをニューラルネットワークに入れるための形式に修正します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1Wd9C0Alfaf"
      },
      "source": [
        "X_train = (((X_train/255.)-0.5)*2.).astype('float32')\n",
        "X_tuning = (((X_tuning/255.)-0.5)*2.).astype('float32')\n",
        "y_train_oh = to_categorical(y_train)\n",
        "y_tuning_oh = to_categorical(y_tuning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JliKgGSXe-r"
      },
      "source": [
        "修正後のデータの次元数と各次元のサイズを確認する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0kyroZMljab"
      },
      "source": [
        "print('X_trainの各次元のサイズ: ', X_train.shape)\n",
        "print('y_trainの各次元のサイズ: ', y_train.shape)\n",
        "print('y_train_ohの各次元のサイズ: ', y_train_oh.shape)\n",
        "print()\n",
        "print('X_tuningの各次元のサイズ: ', X_tuning.shape)\n",
        "print('y_tuningの各次元のサイズ: ', y_tuning.shape)\n",
        "print('y_tuning_ohの各次元のサイズ: ', y_tuning_oh.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX_qVf_3XlqF"
      },
      "source": [
        "テスト用のデータについても同様に読み込んで整形し、同様に次元数と各次元のサイズを確認しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTfMgj95kSsX"
      },
      "source": [
        "img_list_test = []\n",
        "\n",
        "for i in df_test['Image Index']:\n",
        "    img = read_img('test_img_64', i)\n",
        "    img_list_test.append(img)\n",
        "\n",
        "X_test = np.concatenate(img_list_test, axis=0)\n",
        "X_test = (((X_test/255.)-0.5)*2.).astype('float32')\n",
        "\n",
        "y_test = df_test['label']\n",
        "y_test_oh = to_categorical(y_test)\n",
        "\n",
        "print('X_testの各次元のサイズ: ', X_test.shape)\n",
        "print('y_testの各次元のサイズ: ', y_test.shape)\n",
        "print('y_test_ohの各次元のサイズ: ', y_test_oh.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzjklLxJXyGb"
      },
      "source": [
        "ここまででデータの準備が終わりました。ここからはkerasを使ってニューラルネットワークを組んで学習を行います。最初に下記のようなネットワークをとりあえず組んで試してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQlR4JL8hxDj"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=1024, activation='relu'))\n",
        "model.add(Dense(units=2, activation='softmax', name=\"output\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbC0Mr5i5L4u"
      },
      "source": [
        "モデルを表形式で確認しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez6uz8si4_Ae"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMFZre3PX_Um"
      },
      "source": [
        "学習時の条件を設定してモデルをコンパイルします。lossは2分類なのでbinary_crossentropy、optimizerは今回はAdamとしてみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tZHhjC9hxDk"
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsDLuvAAYFJ_"
      },
      "source": [
        "今回は下記を設定して、学習時に2エポック連続でlossが改善しなかったら学習を止めるように設定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUrRE-EYhxDk"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dtEvgyZgfYp"
      },
      "source": [
        "学習開始前にランダムシードを再固定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT2rDImLglgA"
      },
      "source": [
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7yX2c2cYM6U"
      },
      "source": [
        "学習を開始します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXh8bEW1hxDl",
        "scrolled": true
      },
      "source": [
        "history = model.fit(X_train, y_train_oh, \n",
        "                    epochs=10, \n",
        "                    validation_data=(X_tuning, y_tuning_oh), \n",
        "                    batch_size=128, \n",
        "                    shuffle=True, \n",
        "                    callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xroM10MfYljX"
      },
      "source": [
        "下記を実行して学習時のlossの推移を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOBu21EGIjy3"
      },
      "source": [
        "#Loss\n",
        "plt.plot(history.history['loss'],\"o-\",label=\"loss\",)\n",
        "plt.plot(history.history['val_loss'],\"o-\",label=\"val_loss\")\n",
        "plt.title('model loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ARHnk8qYrTe"
      },
      "source": [
        "学習時のaccuracyの推移を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOSwCBLSIbbd"
      },
      "source": [
        "#Accuracy\n",
        "plt.plot(history.history['accuracy'],\"o-\",label=\"accuracy\",)\n",
        "plt.plot(history.history['val_accuracy'],\"o-\",label=\"val_accuracy\")\n",
        "plt.title('model accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXC2izLTZmE3"
      },
      "source": [
        "チューニングデータに対する予測を評価してみます。予測結果をpredictメソッドで取得します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0ju5rijZjTr"
      },
      "source": [
        "y_prob_oh = model.predict(X_tuning, batch_size=128)\n",
        "y_pred = np.argmax(y_prob_oh, axis=1)\n",
        "y_prob = y_prob_oh[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CplQPyylo9yG"
      },
      "source": [
        "sklearnにはspecifisityを算出する関数がなかったので自分で作ります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS9QHk8pZqCg"
      },
      "source": [
        "def specificity_score(true, pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(true, pred).ravel()\n",
        "    return tn / (tn + fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9gzs9pdpFkP"
      },
      "source": [
        "各種評価指標を算出してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "765WmTuNZ1id"
      },
      "source": [
        "print('accuracy: ',accuracy_score(y_tuning, y_pred))    #accuracy: 正解率\n",
        "print('precision: ',precision_score(y_tuning, y_pred))   #precision: 適合率（陽性的中率)\n",
        "print('recall: ',recall_score(y_tuning, y_pred))         #recall: 再現率（感度）\n",
        "print('specificity: ',specificity_score(y_tuning, y_pred))  #specificity: 特異度\n",
        "print('f1 score: ',f1_score(y_tuning, y_pred))               #F1 score: 再現率と適合率の調和平均 2*Precision*Recall/(Precision + Recall)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2rfQKv3pKsC"
      },
      "source": [
        "下記を実行して混同行列を表示してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2raRr8PZ9DH"
      },
      "source": [
        "def plot_confusion_table(true, pred):\n",
        "     sns.heatmap(confusion_matrix(true, pred), annot=True, fmt='g', square=True)\n",
        "     plt.title('confusion matrix')\n",
        "     plt.xlabel('predict')\n",
        "     plt.ylabel('actual')\n",
        "     plt.show()\n",
        "\n",
        "plot_confusion_table(y_tuning, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR1xjUSSpQpA"
      },
      "source": [
        "ROC曲線を描いてAUCを算出してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sszjt-HZZ1Bi"
      },
      "source": [
        "def plot_roc_curve_auc(true, pred):\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(true, pred)\n",
        "\n",
        "    auc = metrics.auc(fpr, tpr)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc)\n",
        "    plt.legend()\n",
        "    plt.title('ROC curve')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.grid(True)\n",
        "\n",
        "plot_roc_curve_auc(y_tuning, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVxEFqYppauQ"
      },
      "source": [
        "caliblation plotを描いてcalibrationの状況を可視化してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Be3Cl8Faft4"
      },
      "source": [
        "def plot_caliblation_curve(true, prob):\n",
        "    prob_true, prob_pred = calibration_curve(true, prob, n_bins=10)\n",
        "    plt.figure()\n",
        "    plt.plot(prob_pred, prob_true, marker='s', label='calibration plot') \n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', label='ideal') \n",
        "    plt.legend(loc='upper left')\n",
        "    plt.title('calibration plot')\n",
        "    plt.xlabel('predict')\n",
        "    plt.ylabel('actual')\n",
        "    plt.show()\n",
        "\n",
        "plot_caliblation_curve(y_tuning, y_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRFCJFafeG85"
      },
      "source": [
        "Grad-CAMという手法を用いて、画像のどの部分が判断に効いているのかを可視化してみます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2WKgbbEppJV"
      },
      "source": [
        "まずtf-keras-visをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4t9KMmVDedK"
      },
      "source": [
        "!pip install tf-keras-vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktvEcDeoptrb"
      },
      "source": [
        "Grad-CAMを描画する関数を下記で定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE99GAlwiaCx"
      },
      "source": [
        "from matplotlib import cm\n",
        "from tf_keras_vis.gradcam import Gradcam\n",
        "from tf_keras_vis.utils import normalize\n",
        "\n",
        "def grad_cam(model, index, img_tensor, label_tensor):\n",
        "\n",
        "    layer_id = 0\n",
        "    output = [model.layers[layer_id].output]\n",
        "\n",
        "    loss = lambda output: tf.keras.backend.mean(output[:, tf.argmax(label_tensor[index])])\n",
        "\n",
        "    def model_modifier(m):\n",
        "        m.layers[-1].activation = tf.keras.activations.linear\n",
        "        return m\n",
        "\n",
        "    gradcam = Gradcam(model, model_modifier, clone=False)\n",
        "    cam = gradcam(loss, img_tensor[index])\n",
        "    cam = normalize(cam)\n",
        "    \n",
        "    heatmap = np.uint8(cm.jet(cam[0])[..., :3] * 255)\n",
        "    if img_tensor.shape[-1] == 1:\n",
        "        plt.imshow(img_tensor[index].reshape((64, 64)))\n",
        "    elif img_tensor.shape[-1] ==3:\n",
        "        plt.imshow(img_tensor[index][:, :, 1].reshape((64, 64)))\n",
        "    plt.imshow(heatmap, cmap='jet', alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzErej2Np0eJ"
      },
      "source": [
        "チューニング用データについてGrad Camを出力して描画した画像を20枚だけ出力してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5mbAKGHdHCZ"
      },
      "source": [
        "fig = plt.figure(figsize=(12, 50))\n",
        "\n",
        "for i in range(20):\n",
        "    plt.subplot(20, 5, i+1)\n",
        "    grad_cam(model, i, X_tuning, y_tuning_oh)\n",
        "    plt.title('label:' + str(y_tuning[y_tuning.index[i]]) + ' pred:' + str(y_pred[i]) + '\\n' + df_train.loc[y_tuning.index[i], 'Finding Labels'])\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1PcOhsbeoVp"
      },
      "source": [
        "上記のようにチューニング用データで評価指標が上がるようにハイパーパラメータを調節し、最終的にはテストデータに対して検証を行います。（本来であればハイパーパラメータを調整してベストのハイパーパラメータを決めて、`X_train`と`X_tuning`を合わせたデータでモデルを学習させて、最後にテスト用データで検証します）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8NgrlWkM8i5"
      },
      "source": [
        "y_prob_test = model.predict(X_test)[:, 1]                             #予測として出力した数値\n",
        "y_pred_test = np.array(y_prob_test >= 0.5).astype(int)         #予測ラベル\n",
        "\n",
        "print('accuracy: ', accuracy_score(y_test, y_pred_test))      #accuracy: 正解率\n",
        "print('precision: ', precision_score(y_test, y_pred_test))      #precision: 適合率（陽性的中率)\n",
        "print('recall: ', recall_score(y_test, y_pred_test))                  #recall: 再現率（感度）\n",
        "print('specificity: ', specificity_score(y_test, y_pred_test))    #specificity: 特異度\n",
        "print('f1 score: ', f1_score(y_test, y_pred_test))                    #F1 score: 再現率と適合率の調和平均 2*Precision*Recall/(Precision + Recall)        \n",
        "\n",
        "plot_confusion_table(y_test, y_pred_test)                            #confusion matrix\n",
        "plot_roc_curve_auc(y_test, y_pred_test)                              #roc curve\n",
        "plot_caliblation_curve(y_test, y_prob_test)                           #calibration plot\n",
        "\n",
        "#Grad-CAM\n",
        "fig = plt.figure(figsize=(12, 50))                                            \n",
        "\n",
        "for i in range(20):\n",
        "    plt.subplot(20, 5, i+1)\n",
        "    grad_cam(model, i, X_test, y_test_oh)\n",
        "    plt.title('lbl:' + str(y_test[y_test.index[i]]) + ' prd:' + str(y_pred_test[i]) + '\\n' + df_test.loc[y_test.index[i], 'Finding Labels'])\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl-_0NWk0uQ7"
      },
      "source": [
        "## 11.NIH chest X-ray Dataset (転移学習)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpF3xElc4JUy"
      },
      "source": [
        "転移学習は、既に学習済みのモデルを追加で学習させることで、新たなモデルを生成する方法です。\n",
        "\n",
        "VGG16という16層からなるCNNモデルを使ってみます。 https://arxiv.org/pdf/1409.1556.pdf\n",
        "\n",
        "ImageNetという画像データセットの120万枚の画像を1000分類するタスクで学習したパラメータが公開されているため、これを利用して追加で学習するようにしてみます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJrcp6tI65rt"
      },
      "source": [
        "VGG16はカラー画像に対するネットワークであるため、入力画像をコピーして3チャンネル分にして、次元のサイズをカラー画像に無理やり合わせます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWJWeSCW53UC"
      },
      "source": [
        "X_train_for_vgg = np.tile(X_train, (1,1,1,3))\n",
        "X_tuning_for_vgg = np.tile(X_tuning, (1,1,1,3))\n",
        "X_test_for_vgg = np.tile(X_test, (1,1,1,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2UfeSgr7Q_m"
      },
      "source": [
        "print(X_train_for_vgg.shape)\n",
        "print(X_tuning_for_vgg.shape)\n",
        "print(X_test_for_vgg.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcO3q4Oe7nLn"
      },
      "source": [
        "下記のようにVGG16を呼び出してオプションでweightにimagenetを設定します。元々1000分類用のネットワークなのですが、including_top=Falseで最後のレイヤーは読み込まず、最後が2分類の0 or 1がsoftmax関数で出力するようにレイヤーを追加しています。元々のネットワークは学習せずに、追加したレイヤーだけ学習するように設定しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2g-2K8ru0No"
      },
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=None,  input_shape=None)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "vgg_model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "   layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y-PEEW045bx"
      },
      "source": [
        "vgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0VvFMW9gt_7"
      },
      "source": [
        "#学習開始前にランダムシードを再固定。\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbphoje7hxD-"
      },
      "source": [
        "vgg_model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
        "history = vgg_model.fit(X_train_for_vgg, y_train_oh, \n",
        "                                     epochs=10, \n",
        "                                     validation_data=(X_tuning_for_vgg, y_tuning_oh), \n",
        "                                     batch_size=128, \n",
        "                                     shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk-P7wuy33UJ"
      },
      "source": [
        "y_prob_test_vgg = vgg_model.predict(X_test_for_vgg)[:, 1]                             #予測として出力した数値\n",
        "y_pred_test_vgg = np.array(y_prob_test_vgg >= 0.5).astype(int)         #予測ラベル\n",
        "\n",
        "print('accuracy: ', accuracy_score(y_test, y_pred_test_vgg))      #accuracy: 正解率\n",
        "print('precision: ', precision_score(y_test, y_pred_test_vgg))      #precision: 適合率（陽性的中率)\n",
        "print('recall: ', recall_score(y_test, y_pred_test_vgg))                  #recall: 再現率（感度）\n",
        "print('specificity: ', specificity_score(y_test, y_pred_test_vgg))    #specificity: 特異度\n",
        "print('f1 score: ', f1_score(y_test, y_pred_test_vgg))                    #F1 score: 再現率と適合率の調和平均 2*Precision*Recall/(Precision + Recall)        \n",
        "\n",
        "plot_confusion_table(y_test, y_pred_test_vgg)                            #confusion matrix\n",
        "plot_roc_curve_auc(y_test, y_pred_test_vgg)                              #roc curve\n",
        "plot_caliblation_curve(y_test, y_prob_test_vgg)                           #calibration plot\n",
        "\n",
        "#Grad-CAM\n",
        "fig = plt.figure(figsize=(12, 50))                                            \n",
        "\n",
        "for i in range(20):\n",
        "    plt.subplot(20, 5, i+1)\n",
        "    grad_cam(vgg_model, i, X_test_for_vgg, y_test_oh)\n",
        "    plt.title('label:' + str(y_test[y_test.index[i]]) + ' pred:' + str(y_pred_test_vgg[i]) + '\\n' + df_test.loc[y_test.index[i], 'Finding Labels'])\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSB1pXkq0_41"
      },
      "source": [
        "## 12.発展問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YZd_9HcHdCb"
      },
      "source": [
        "mnistのデータを対象にして、モデルの性能が上がるように試行錯誤してみることとします。画像データを使った深層学習でよく使う手法として、画像をずらしたり回転させたりして学習データの効果を増強するオーグメンテーションがあり、下ではkerasのImageDataGenerator関数を使って画像のオーグメンテーションを行っています。\n",
        "\n",
        "下記のセルを実行し、プログラムが空いているところを埋めて、トレーニングデータで学習したモデルの性能をチューニングデータで検証し、最後にテストデータに対してaccuracy 99%、F1スコア 0.99を超えるモデルを作ってみてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kKqRPWQgjZx"
      },
      "source": [
        "###このセルはそのまま実行してください。\n",
        "%reset  #一旦インポートしたモジュールの情報や作成した変数をリセットしてメモリを空ける\n",
        "\n",
        "#このセルを実行すると、Once deleted, variables cannot be recovered. Proceed (y/[n])? と聞かれるので、y と入力してエンターキーを押す。"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD3gXW5ezERP"
      },
      "source": [
        "###このセルはそのまま実行してください。\n",
        "##もう一度下記をインポートする\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import scipy\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import imageio\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.models import Model, model_from_json, Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "#実習用に下記でランダムシードを固定する。\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp1N1SIACMdE"
      },
      "source": [
        "###このセルはそのまま実行してください。\n",
        "##データ読み込み、前処理用のセル\n",
        "#mnistデータの読み込み\n",
        "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()\n",
        "\n",
        "#読み込んだ後のデータの各次元のサイズを確認\n",
        "print(\"データ読み込み後\")\n",
        "print('X_train_mnistの各次元のサイズ: ', X_train_mnist.shape)\n",
        "print('y_train_mnistの各次元のサイズ: ', y_train_mnist.shape)\n",
        "print('X_test_mnistの各次元のサイズ: ', X_test_mnist.shape)\n",
        "print('y_test_mnistの各次元のサイズ: ', y_test_mnist.shape)\n",
        "print()\n",
        "\n",
        "#X_train_mnist, y_train_mnistから、scikit-learnのtrain_test_splitを使ってX_tuning_mnist、y_tuning_mnistを切り出す\n",
        "X_train_mnist, X_tuning_mnist, y_train_mnist, y_tuning_mnist = train_test_split(X_train_mnist, y_train_mnist, test_size=0.2, random_state=0)\n",
        "\n",
        "#X_train_mnistの次元を(枚数、28, 28, チャンネル数)に変換したのち、0-255のピクセル値を-1から1の値にスケーリングする\n",
        "X_train_mnist = X_train_mnist.reshape(X_train_mnist.shape[0],28,28,1).astype('float32')\n",
        "X_train_mnist = ((X_train_mnist/255.)-0.5)*2.\n",
        "\n",
        "#y_train_mnistをone-hot表現に変換してy_train_mnist_ohという変数に入れておく\n",
        "y_train_mnist_oh = to_categorical(y_train_mnist)\n",
        "\n",
        "#X_tuning_mnistの次元を(枚数、28, 28, チャンネル数)に変換したのち、0-255のピクセル値を-1から1の値にスケーリングする\n",
        "X_tuning_mnist = X_tuning_mnist.reshape(X_tuning_mnist.shape[0],28,28,1).astype('float32')\n",
        "X_tuning_mnist = ((X_tuning_mnist/255.)-0.5)*2.\n",
        "\n",
        "#y_tuning_mnistをone-hot表現に変換してy_tuning_mnist_ohという変数に入れておく\n",
        "y_tuning_mnist_oh = to_categorical(y_tuning_mnist)\n",
        "\n",
        "#X_test_mnistの次元を(枚数、28, 28, チャンネル数)に変換したのち、0-255のピクセル値を-1から1の値にスケーリングする\n",
        "X_test_mnist = X_test_mnist.reshape(X_test_mnist.shape[0],28,28,1).astype('float32')\n",
        "X_test_mnist = ((X_test_mnist/255.)-0.5)*2.\n",
        "\n",
        "#y_test_mnistをone-hot表現に変換してy_test_mnist_ohという変数に入れておく\n",
        "y_test_mnist_oh = to_categorical(y_test_mnist)\n",
        "\n",
        "#データ整形後の各次元のサイズを確認\n",
        "print(\"データ整形後\")\n",
        "print('X_train_mnistの各次元のサイズ: ', X_train_mnist.shape)\n",
        "print('y_train_mnistの各次元のサイズ: ', y_train_mnist.shape)\n",
        "print('y_train_mnist_ohの各次元のサイズ: ', y_train_mnist_oh.shape)\n",
        "print()\n",
        "print('X_tuning_mnistの各次元のサイズ: ', X_tuning_mnist.shape)\n",
        "print('y_tuning_mnistの各次元のサイズ: ', y_tuning_mnist.shape)\n",
        "print('y_tuning_mnist_ohの各次元のサイズ: ', y_tuning_mnist_oh.shape)\n",
        "print()\n",
        "print('X_test_mnistの各次元のサイズ: ', X_test_mnist.shape)\n",
        "print('y_test_mnistの各次元のサイズ: ', y_test_mnist.shape)\n",
        "print('y_test_mnist_ohの各次元のサイズ: ', y_test_mnist.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBjf2V2GLJU7"
      },
      "source": [
        "下のセルのepoch_num、optimizer_type、batch_size_num、rotation_range、width_shift_range、height_shift_range、zoom_rangeの値について、値を考えて代入してください。\n",
        "また、「ここにニューラルネットワークを定義するスクリプトを記載します。」の部分にニューラルネットワークを定義するスクリプトを作って書き込んで、セルを実行してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VESHbz7VCLqO"
      },
      "source": [
        "epoch_num =                              #エポック数（学習データを何周するか）を決めます。(記入例：epock_num = 10 のように決めます)\n",
        "optimizer_type =                         #最適化のための手法を決めます。(記入例：optimizer_type = SGD(lr=0.01) のように決めます)\n",
        "batch_size_num =                      #学習時のバッチサイズを決めます。(記入例：batch_size_num =  128 のように決めます)\n",
        "rotation_range =                         #画像をランダムに回転する回転範囲を決めます。(記入例：rotation_range = 20 のように決めます)\n",
        "width_shift_range =                    #ランダムに水平シフトする範囲を決めます。(記入例：width_shift_range = 0.2 のように決めます)\n",
        "height_shift_range =                   #ランダムに垂直シフトする範囲を決めます。(記入例：height_shift_range = 0.2 のように決めます)\n",
        "zoom_range =                             #ランダムにズームする比率を決めます。(記入例：rzoom_range = 0.2  のように決めます)\n",
        "\n",
        "mnist_model_new = Sequential()\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#ここにニューラルネットワークを定義するスクリプトを記載します。\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "mnist_model_new.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "mnist_model_new.compile(loss=\"categorical_crossentropy\", optimizer=optimizer_type, metrics=[\"accuracy\"])\n",
        "mnist_model_new.summary()\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=rotation_range,                           \n",
        "                                                    width_shift_range=width_shift_range,              \n",
        "                                                    height_shift_range=height_shift_range,             \n",
        "                                                    zoom_range = zoom_range)                             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwkOQZHlg_y6"
      },
      "source": [
        "#学習開始前に下記でランダムシードを再固定\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ger-idmuPnzM"
      },
      "source": [
        "下のセルを実行して学習を開始します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM3ck8srD7M_"
      },
      "source": [
        "###このセルは、一つ前のセルのプログラムを埋めてエラーなく実行できるようになったら、その後にそのままこのセルを実行してください。\n",
        "#学習開始\n",
        "history = mnist_model_new.fit(datagen.flow(X_train_mnist, y_train_mnist_oh, batch_size=128), \n",
        "                                                epochs=epoch_num, \n",
        "                                                validation_data=(X_tuning_mnist, y_tuning_mnist_oh), \n",
        "                                                batch_size= batch_size_num, \n",
        "                                                shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d5N-3IgH0Bg"
      },
      "source": [
        "下記を実行してテストデータに対してaccuracyとf1 scoreを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIi6aXZXD6pQ"
      },
      "source": [
        "###このセルは一つ前のセルの学習が終わったら、そのまま実行してください。\n",
        "y_pred_mnist = mnist_model_new.predict(X_test_mnist, batch_size=128)\n",
        "y_pred_mnist = np.argmax(y_pred_mnist, axis=1)\n",
        "print('accuracy:', accuracy_score(y_test_mnist, y_pred_mnist))    \n",
        "print('f1 score:',f1_score(y_test_mnist, y_pred_mnist, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wb7K_zIE1At"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZqNJ4soE42j"
      },
      "source": [
        "### 回答例1\n",
        "ニューラルネットワークを深めにして、エポックを50に設定したケースです。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcvt3HOZE3_N"
      },
      "source": [
        "epoch_num =  50                           \n",
        "optimizer_type = SGD(lr=0.01)                    \n",
        "batch_size_num =  128                     \n",
        "rotation_range =  10                      \n",
        "width_shift_range = 0.1                   \n",
        "height_shift_range =  0.1                \n",
        "zoom_range = 0.1                        \n",
        "\n",
        "mnist_model_new = Sequential()\n",
        "mnist_model_new.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "mnist_model_new.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "mnist_model_new.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "mnist_model_new.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "mnist_model_new.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "mnist_model_new.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "mnist_model_new.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
        "mnist_model_new.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "mnist_model_new.add(Flatten())\n",
        "mnist_model_new.add(Dense(units=512, activation='relu'))\n",
        "mnist_model_new.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "mnist_model_new.compile(loss=\"categorical_crossentropy\", optimizer=optimizer_type, metrics=[\"accuracy\"])\n",
        "mnist_model_new.summary()\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=rotation_range,                           \n",
        "                                                    width_shift_range=width_shift_range,              \n",
        "                                                    height_shift_range=height_shift_range,             \n",
        "                                                    zoom_range = zoom_range)                             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9kGvxN0FGvi"
      },
      "source": [
        "#学習開始\n",
        "history = mnist_model_new.fit(datagen.flow(X_train_mnist, y_train_mnist_oh, batch_size=batch_size_num), \n",
        "                                                epochs=epoch_num, \n",
        "                                                validation_data=(X_tuning_mnist, y_tuning_mnist_oh), \n",
        "                                                batch_size= batch_size_num, \n",
        "                                                shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4fjQbQ9E0bl"
      },
      "source": [
        "y_pred_mnist = mnist_model_new.predict(X_test_mnist, batch_size=128)\n",
        "y_pred_mnist = np.argmax(y_pred_mnist, axis=1)\n",
        "print('accuracy:', accuracy_score(y_test_mnist, y_pred_mnist))    \n",
        "print('f1 score:',f1_score(y_test_mnist, y_pred_mnist, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9EagD8sFLN-"
      },
      "source": [
        "### 回答例2\n",
        "最適化の手法をAdamという手法でやってみた場合です。ネットワークの構造や画像の回転やずらす範囲なども回答例1とは変えてみた例です。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYKI5KsIFn9Z"
      },
      "source": [
        "epoch_num =  10                           \n",
        "optimizer_type = Adam(lr=0.001)                    \n",
        "batch_size_num =  128                     \n",
        "rotation_range =  20                      \n",
        "width_shift_range = 0.15                   \n",
        "height_shift_range =  0.15                \n",
        "zoom_range = 0.15                        \n",
        "\n",
        "mnist_model_new = Sequential()\n",
        "\n",
        "mnist_model_new.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "mnist_model_new.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "mnist_model_new.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "mnist_model_new.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "mnist_model_new.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "mnist_model_new.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "mnist_model_new.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "mnist_model_new.add(Flatten())\n",
        "mnist_model_new.add(Dense(units=512, activation='relu'))\n",
        "mnist_model_new.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "mnist_model_new.compile(loss=\"categorical_crossentropy\", optimizer=optimizer_type, metrics=[\"accuracy\"])\n",
        "mnist_model_new.summary()\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=rotation_range,                           \n",
        "                                                    width_shift_range=width_shift_range,              \n",
        "                                                    height_shift_range=height_shift_range,             \n",
        "                                                    zoom_range = zoom_range)                             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcsCgm33FrkB"
      },
      "source": [
        "#学習開始\n",
        "history = mnist_model_new.fit(datagen.flow(X_train_mnist, y_train_mnist_oh, batch_size=batch_size_num), \n",
        "                                                epochs=epoch_num, \n",
        "                                                validation_data=(X_tuning_mnist, y_tuning_mnist_oh), \n",
        "                                                batch_size= batch_size_num, \n",
        "                                                shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t0GmL29Fu_q"
      },
      "source": [
        "y_pred_mnist = mnist_model_new.predict(X_test_mnist, batch_size=128)\n",
        "y_pred_mnist = np.argmax(y_pred_mnist, axis=1)\n",
        "print('accuracy:', accuracy_score(y_test_mnist, y_pred_mnist))    \n",
        "print('f1 score:',f1_score(y_test_mnist, y_pred_mnist, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K1ahBf3Fz0w"
      },
      "source": [
        "### 回答例3\n",
        "batch normalizationという手法でレイヤーレベルでデータの正規化を行うと学習効率がよくなり過学習も防げることが知られています。\n",
        "https://keras.io/ja/layers/normalization/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uumndPaCFKdX"
      },
      "source": [
        "epoch_num =  10                           \n",
        "optimizer_type = SGD(lr=0.01)                    \n",
        "batch_size_num =  128                     \n",
        "rotation_range =  10                      \n",
        "width_shift_range = 0.1                   \n",
        "height_shift_range =  0.1                \n",
        "zoom_range = 0.1                        \n",
        "\n",
        "mnist_model_new = Sequential()\n",
        "mnist_model_new.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "mnist_model_new.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "mnist_model_new.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "mnist_model_new.add(BatchNormalization())\n",
        "\n",
        "mnist_model_new.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "mnist_model_new.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "mnist_model_new.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "mnist_model_new.add(BatchNormalization())\n",
        "\n",
        "mnist_model_new.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
        "mnist_model_new.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "mnist_model_new.add(Flatten())\n",
        "mnist_model_new.add(BatchNormalization())\n",
        "mnist_model_new.add(Dense(units=512, activation='relu'))\n",
        "mnist_model_new.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "mnist_model_new.compile(loss=\"categorical_crossentropy\", optimizer=optimizer_type, metrics=[\"accuracy\"])\n",
        "mnist_model_new.summary()\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=rotation_range,                           \n",
        "                                                    width_shift_range=width_shift_range,              \n",
        "                                                    height_shift_range=height_shift_range,             \n",
        "                                                    zoom_range = zoom_range)                             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8tus8GkFKBs"
      },
      "source": [
        "#学習開始\n",
        "history = mnist_model_new.fit(datagen.flow(X_train_mnist, y_train_mnist_oh, batch_size=batch_size_num), \n",
        "                                                epochs=epoch_num, \n",
        "                                                validation_data=(X_tuning_mnist, y_tuning_mnist_oh), \n",
        "                                                batch_size= batch_size_num, \n",
        "                                                shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eitIrApF4mt"
      },
      "source": [
        "y_pred_mnist = mnist_model_new.predict(X_test_mnist, batch_size=128)\n",
        "y_pred_mnist = np.argmax(y_pred_mnist, axis=1)\n",
        "print('accuracy:', accuracy_score(y_test_mnist, y_pred_mnist))    \n",
        "print('f1 score:',f1_score(y_test_mnist, y_pred_mnist, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXvRYr3qFXph"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}